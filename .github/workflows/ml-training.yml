name: ML Training Pipeline

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'src/training/**'
      - 'src/data_processing/**'
      - 'src/dataset_generation/**'
      - 'config/**'
      - 'data/datasets/**'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/training/**'
      - 'src/data_processing/**'
      - 'src/dataset_generation/**'
      - 'config/**'
      - 'data/datasets/**'
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Model to train'
        required: true
        default: 'Qwen/Qwen1.5-0.5B-Chat'
      dataset_name:
        description: 'Dataset to use'
        required: true
        default: 'egypt_tourism'

env:
  PYTHON_VERSION: "3.11"
  HF_TOKEN: ${{ secrets.HF_TOKEN }}
  WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}

jobs:
  data-validation:
    name: Data Validation
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Validate Egypt tourism datasets
      run: |
        python -c "
        import json
        import sys
        from pathlib import Path
        
        print('üîç Validating Egypt tourism datasets...')
        
        # Check if datasets exist
        dataset_path = Path('data/datasets/splits')
        required_files = ['egypt_tourism_train.json', 'egypt_tourism_val.json', 'egypt_tourism_test.json']
        
        for file in required_files:
            file_path = dataset_path / file
            if not file_path.exists():
                print(f'‚ùå Missing dataset file: {file}')
                sys.exit(1)
            print(f'‚úÖ Found: {file}')
            
            # Validate JSON structure
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # Check required fields
                if 'metadata' not in data:
                    print(f'‚ùå {file}: Missing metadata field')
                    sys.exit(1)
                if 'data' not in data:
                    print(f'‚ùå {file}: Missing data field')
                    sys.exit(1)
                
                # Check data samples
                samples = data['data']
                if not samples:
                    print(f'‚ùå {file}: No data samples found')
                    sys.exit(1)
                
                print(f'‚úÖ {file}: {len(samples)} samples, format: {data.get(\"metadata\", {}).get(\"format\", \"unknown\")}')
                
                # Validate sample structure
                for i, sample in enumerate(samples[:5]):  # Check first 5 samples
                    if 'instruction' not in sample:
                        print(f'‚ùå {file}: Sample {i} missing instruction field')
                        sys.exit(1)
                    if 'output' not in sample:
                        print(f'‚ùå {file}: Sample {i} missing output field')
                        sys.exit(1)
                        
            except json.JSONDecodeError as e:
                print(f'‚ùå {file}: Invalid JSON - {e}')
                sys.exit(1)
            except Exception as e:
                print(f'‚ùå {file}: Error reading file - {e}')
                sys.exit(1)
        
        print('üéâ All datasets validated successfully!')
        "
        
    - name: Check data quality
      run: |
        python scripts/test_huggingface.py

  model-training:
    name: Model Training
    runs-on: ubuntu-latest
    needs: [data-validation]
    
    strategy:
      matrix:
        config: [very_fast, fast]
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Train Egypt tourism model
      run: |
        echo "Training Egypt tourism model with ${{ matrix.config }} configuration"
        python main.py train
        # Note: In CI, we use the very_fast config to keep training time reasonable
        
    - name: Upload model artifacts
      uses: actions/upload-artifact@v4
      with:
        name: egypt-tourism-model-${{ matrix.config }}
        path: |
          models/egypt_tourism_assistant/
        retention-days: 30

  model-evaluation:
    name: Model Evaluation
    runs-on: ubuntu-latest
    needs: [model-training]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Download model artifacts
      uses: actions/download-artifact@v4
      with:
        path: models/
        
    - name: Run benchmark evaluation
      run: |
        echo "Running benchmark evaluation..."
        python main.py benchmark
        
    - name: Upload evaluation results
      uses: actions/upload-artifact@v4
      with:
        name: evaluation-results
        path: |
          data/benchmark/
          *.json
          *.csv
        retention-days: 90

  model-deployment:
    name: Model Deployment
    runs-on: ubuntu-latest
    needs: [model-evaluation]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Download evaluation results
      uses: actions/download-artifact@v4
      with:
        name: evaluation-results
        path: evaluation/
        
    - name: Test API deployment
      run: |
        echo "Testing API deployment..."
        # Start API server in background
        python main.py serve --host 127.0.0.1 --port 8000 &
        sleep 10
        
        # Test health endpoint
        curl -f http://127.0.0.1:8000/health || exit 1
        
        # Test prediction endpoint
        curl -X POST http://127.0.0.1:8000/predict \
          -H "Content-Type: application/json" \
          -d '{"question": "What are the best attractions in Egypt?"}' || exit 1
        
        echo "‚úÖ API deployment test passed"
        
    - name: Update deployment status
      run: |
        echo "üéâ Model deployment completed successfully!"
        echo "API is ready for production use" 